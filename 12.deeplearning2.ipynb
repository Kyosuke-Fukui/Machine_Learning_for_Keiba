{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d558b2c413fa4126b259b70291aaa4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2074bcf1ebaf49ce89d5c057c644d101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a236c36a294d2eb4a0b03811c81e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4527745b967d4822b97c11d6052558cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owner\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#多クラス分類\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "train = FashionMNIST('FashionMNIST', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = FashionMNIST('FashionMNIST', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#１０種類の画像を分類（判別）できるか\n",
    "X_train = train.data.type(torch.float32)\n",
    "t_train = train.targets\n",
    "X_test = test.data.type(torch.float32)\n",
    "t_test = test.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24a4dcb1748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAR1ElEQVR4nO3dbYyV5ZkH8P9fXlRe5EVEhpcIVoxsNi6sIxpBU60Q9INQtVg+NBh1aUxN2qQma9wPNfGDRLdt9gNpMlVTunZtmhQixrcS0sRuwMpIWECmrYBYBsYBBIHhbRi49sM8mCnOc13jec45z5H7/0vIzJxr7nPuc878OWfmeu7npplBRC5+l5Q9ARGpD4VdJBEKu0giFHaRRCjsIokYXM8bI6k//YvUmJmxv8sLvbKTXEDyryR3kHyqyHWJSG2x0j47yUEA/gZgHoB2ABsBLDGz7c4YvbKL1FgtXtlnA9hhZrvMrBvAbwEsLHB9IlJDRcI+CcCePl+3Z5f9A5LLSLaSbC1wWyJSUJE/0PX3VuFLb9PNrAVAC6C38SJlKvLK3g5gSp+vJwPYV2w6IlIrRcK+EcB0ktNIDgXwXQBrqjMtEam2it/Gm1kPyScAvANgEICXzezDqs1MRKqq4tZbRTem39lFaq4mB9WIyNeHwi6SCIVdJBEKu0giFHaRRCjsIolQ2EUSobCLJEJhF0mEwi6SCIVdJBEKu0giFHaRRNT1VNJSf2S/C6C+UHTV48iRI9363Llzc2tvvfVWoduO7tugQYNyaz09PYVuu6ho7p5KnzO9soskQmEXSYTCLpIIhV0kEQq7SCIUdpFEKOwiiVCf/SJ3ySX+/+dnz55169ddd51bf+yxx9z6yZMnc2vHjx93x546dcqtv//++269SC896oNHj2s0vsjcvOMHvOdTr+wiiVDYRRKhsIskQmEXSYTCLpIIhV0kEQq7SCLUZ7/IeT1ZIO6z33XXXW797rvvduvt7e25tUsvvdQdO2zYMLc+b948t/7iiy/m1jo7O92x0Zrx6HGLjBgxIrd27tw5d+yJEycqus1CYSe5G8AxAGcB9JhZc5HrE5HaqcYr+51mdrAK1yMiNaTf2UUSUTTsBuAPJD8guay/byC5jGQrydaCtyUiBRR9Gz/HzPaRHA9gLcm/mNm7fb/BzFoAtAAAyWJnNxSRihV6ZTezfdnH/QBWA5hdjUmJSPVVHHaSw0mOPP85gPkAtlVrYiJSXUXexl8NYHW2bncwgP8xs7erMiupmu7u7kLjb775Zrc+depUt+71+aM14e+8845bnzVrllt//vnnc2utrf6fkLZu3erW29ra3Prs2f6bXO9xXb9+vTt2w4YNubWurq7cWsVhN7NdAP6l0vEiUl9qvYkkQmEXSYTCLpIIhV0kEQq7SCJYdMver3RjOoKuJrzTFkfPb7RM1GtfAcDo0aPd+pkzZ3Jr0VLOyMaNG936jh07cmtFW5JNTU1u3bvfgD/3Bx980B27YsWK3FprayuOHj3a7w+EXtlFEqGwiyRCYRdJhMIukgiFXSQRCrtIIhR2kUSoz94Aou19i4ie3/fee8+tR0tYI959i7YtLtoL97Z8jnr8mzZtcuteDx+I79uCBQtya9dee607dtKkSW7dzNRnF0mZwi6SCIVdJBEKu0giFHaRRCjsIolQ2EUSoS2bG0A9j3W40OHDh916tG775MmTbt3blnnwYP/Hz9vWGPD76ABw+eWX59aiPvvtt9/u1m+77Ta3Hp0me/z48bm1t9+uzRnZ9coukgiFXSQRCrtIIhR2kUQo7CKJUNhFEqGwiyRCffbEDRs2zK1H/eKofuLEidzakSNH3LGfffaZW4/W2nvHL0TnEIjuV/S4nT171q17ff4pU6a4YysVvrKTfJnkfpLb+lw2luRakh9lH8fUZHYiUjUDeRv/KwAXnlbjKQDrzGw6gHXZ1yLSwMKwm9m7AA5dcPFCACuzz1cCWFTleYlIlVX6O/vVZtYBAGbWQTL3QF+SywAsq/B2RKRKav4HOjNrAdAC6ISTImWqtPXWSbIJALKP+6s3JRGphUrDvgbA0uzzpQBeq850RKRWwrfxJF8F8E0A40i2A/gJgOUAfkfyUQB/B/CdWk7yYle05+v1dKM14RMnTnTrp0+fLlT31rNH54X3evRAvDe816eP+uRDhw5168eOHXPro0aNcutbtmzJrUXPWXNzc25t+/btubUw7Ga2JKf0rWisiDQOHS4rkgiFXSQRCrtIIhR2kUQo7CKJ0BLXBhCdSnrQoEFu3Wu9PfTQQ+7YCRMmuPUDBw64de90zYC/lHP48OHu2GipZ9S689p+Z86cccdGp7mO7veVV17p1lesWJFbmzlzpjvWm5vXxtUru0giFHaRRCjsIolQ2EUSobCLJEJhF0mEwi6SCNZzu2CdqaZ/UU+3p6en4uu+5ZZb3Pobb7zh1qMtmYscAzBy5Eh3bLQlc3Sq6SFDhlRUA+JjAKKtriPefXvhhRfcsa+88opbN7N+m+16ZRdJhMIukgiFXSQRCrtIIhR2kUQo7CKJUNhFEvG1Ws/urdWN+r3R6Zij0zl765+9NdsDUaSPHnnzzTfd+vHjx9161GePTrnsHccRrZWPntPLLrvMrUdr1ouMjZ7zaO433nhjbi3ayrpSemUXSYTCLpIIhV0kEQq7SCIUdpFEKOwiiVDYRRLRUH32Imuja9mrrrU77rjDrT/wwANufc6cObm1aNvjaE141EeP1uJ7z1k0t+jnwTsvPOD34aPzOERzi0SPW1dXV27t/vvvd8e+/vrrFc0pfGUn+TLJ/SS39bnsGZJ7SW7O/t1b0a2LSN0M5G38rwAs6Ofyn5vZzOyff5iWiJQuDLuZvQvgUB3mIiI1VOQPdE+Q3JK9zR+T900kl5FsJdla4LZEpKBKw/4LAN8AMBNAB4Cf5n2jmbWYWbOZNVd4WyJSBRWF3cw6zeysmZ0D8EsAs6s7LRGptorCTrKpz5ffBrAt73tFpDGE540n+SqAbwIYB6ATwE+yr2cCMAC7AXzfzDrCGyvxvPFjx4516xMnTnTr06dPr3hs1De9/vrr3frp06fdurdWP1qXHe0zvm/fPrcenX/d6zdHe5hH+68PGzbMra9fvz63NmLECHdsdOxDtJ49WpPuPW6dnZ3u2BkzZrj1vPPGhwfVmNmSfi5+KRonIo1Fh8uKJEJhF0mEwi6SCIVdJBEKu0giGmrL5ltvvdUd/+yzz+bWrrrqKnfs6NGj3bq3FBPwl1t+/vnn7tho+W3UQopaUN5psKNTQbe1tbn1xYsXu/XWVv8oaG9b5jFjco+yBgBMnTrVrUd27dqVW4u2iz527Jhbj5bARi1Nr/V3xRVXuGOjnxdt2SySOIVdJBEKu0giFHaRRCjsIolQ2EUSobCLJKLufXavX71hwwZ3fFNTU24t6pNH9SKnDo5OeRz1uosaNWpUbm3cuHHu2Icfftitz58/360//vjjbt1bInvq1Cl37Mcff+zWvT464C9LLrq8NlraG/XxvfHR8tlrrrnGravPLpI4hV0kEQq7SCIUdpFEKOwiiVDYRRKhsIskoq599nHjxtl9992XW1++fLk7fufOnbm16NTAUT3a/tcT9Vy9PjgA7Nmzx61Hp3P21vJ7p5kGgAkTJrj1RYsWuXVvW2TAX5MePSc33XRTobp336M+evS4RVsyR7xzEEQ/T955Hz799FN0d3erzy6SMoVdJBEKu0giFHaRRCjsIolQ2EUSobCLJCLcxbWaenp6sH///tx61G/21ghH2xpH1x31fL2+anSe70OHDrn1Tz75xK1Hc/PWy0drxqNz2q9evdqtb9261a17ffZoG+2oFx6dr9/brjq639Ga8qgXHo33+uxRD9/b4tt7TMJXdpJTSP6RZBvJD0n+MLt8LMm1JD/KPvpn/BeRUg3kbXwPgB+b2QwAtwL4Acl/AvAUgHVmNh3AuuxrEWlQYdjNrMPMNmWfHwPQBmASgIUAVmbfthKAf1yliJTqK/2BjuRUALMA/BnA1WbWAfT+hwBgfM6YZSRbSbZGv4OJSO0MOOwkRwD4PYAfmdnRgY4zsxYzazaz5qKLB0SkcgMKO8kh6A36b8xsVXZxJ8mmrN4EIP/P7CJSurD1xt4ewUsA2szsZ31KawAsBbA8+/hadF3d3d3Yu3dvbj1abtve3p5bGz58uDs2OqVy1MY5ePBgbu3AgQPu2MGD/Yc5Wl4btXm8ZabRKY2jpZze/QaAGTNmuPXjx4/n1qJ26OHDh9169Lh5c/fackDcmovGR1s2e0uLjxw54o6dOXNmbm3btm25tYH02ecA+B6ArSQ3Z5c9jd6Q/47kowD+DuA7A7guESlJGHYz+18AeUcAfKu60xGRWtHhsiKJUNhFEqGwiyRCYRdJhMIukoi6LnE9efIkNm/enFtftWpVbg0AHnnkkdxadLrlaHvfaCmot8w06oNHPdfoyMJoS2hveW+0VXV0bEO0lXVHR0fF1x/NLTo+ochzVnT5bJHltYDfx582bZo7trOzs6Lb1Su7SCIUdpFEKOwiiVDYRRKhsIskQmEXSYTCLpKIum7ZTLLQjd1zzz25tSeffNIdO358v2fN+kK0btvrq0b94qhPHvXZo36zd/3eKYuBuM8eHUMQ1b37Fo2N5h7xxnu96oGInrPoVNLeevYtW7a4YxcvXuzWzUxbNoukTGEXSYTCLpIIhV0kEQq7SCIUdpFEKOwiiah7n907T3nUmyzizjvvdOvPPfecW/f69KNGjXLHRudmj/rwUZ896vN7vC20gbgP7+0DAPjPaVdXlzs2elwi3tyj9ebROv7oOV27dq1bb2try62tX7/eHRtRn10kcQq7SCIUdpFEKOwiiVDYRRKhsIskQmEXSUTYZyc5BcCvAUwAcA5Ai5n9F8lnAPwbgPObkz9tZm8G11W/pn4d3XDDDW696N7wkydPduu7d+/OrUX95J07d7p1+frJ67MPZJOIHgA/NrNNJEcC+IDk+SMGfm5m/1mtSYpI7Qxkf/YOAB3Z58dItgGYVOuJiUh1faXf2UlOBTALwJ+zi54guYXkyyTH5IxZRrKVZGuhmYpIIQMOO8kRAH4P4EdmdhTALwB8A8BM9L7y/7S/cWbWYmbNZtZchfmKSIUGFHaSQ9Ab9N+Y2SoAMLNOMztrZucA/BLA7NpNU0SKCsPO3lN0vgSgzcx+1ufypj7f9m0A26o/PRGploG03uYC+BOArehtvQHA0wCWoPctvAHYDeD72R/zvOu6KFtvIo0kr/X2tTpvvIjEtJ5dJHEKu0giFHaRRCjsIolQ2EUSobCLJEJhF0mEwi6SCIVdJBEKu0giFHaRRCjsIolQ2EUSobCLJGIgZ5etpoMAPunz9bjsskbUqHNr1HkBmlulqjm3a/IKdV3P/qUbJ1sb9dx0jTq3Rp0XoLlVql5z09t4kUQo7CKJKDvsLSXfvqdR59ao8wI0t0rVZW6l/s4uIvVT9iu7iNSJwi6SiFLCTnIByb+S3EHyqTLmkIfkbpJbSW4ue3+6bA+9/SS39blsLMm1JD/KPva7x15Jc3uG5N7ssdtM8t6S5jaF5B9JtpH8kOQPs8tLfeycedXlcav77+wkBwH4G4B5ANoBbASwxMy213UiOUjuBtBsZqUfgEHyDgBdAH5tZv+cXfY8gENmtjz7j3KMmf17g8ztGQBdZW/jne1W1NR3m3EAiwA8jBIfO2dei1GHx62MV/bZAHaY2S4z6wbwWwALS5hHwzOzdwEcuuDihQBWZp+vRO8PS93lzK0hmFmHmW3KPj8G4Pw246U+ds686qKMsE8CsKfP1+1orP3eDcAfSH5AclnZk+nH1ee32co+ji95PhcKt/Gupwu2GW+Yx66S7c+LKiPs/W1N00j9vzlm9q8A7gHwg+ztqgzMgLbxrpd+thlvCJVuf15UGWFvBzClz9eTAewrYR79MrN92cf9AFaj8bai7jy/g272cX/J8/lCI23j3d8242iAx67M7c/LCPtGANNJTiM5FMB3AawpYR5fQnJ49ocTkBwOYD4abyvqNQCWZp8vBfBaiXP5B42yjXfeNuMo+bErfftzM6v7PwD3ovcv8jsB/EcZc8iZ17UA/i/792HZcwPwKnrf1p1B7zuiRwFcCWAdgI+yj2MbaG7/jd6tvbegN1hNJc1tLnp/NdwCYHP2796yHztnXnV53HS4rEgidASdSCIUdpFEKOwiiVDYRRKhsIskQmEXSYTCLpKI/wfWXDGbEgNvhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           1.,   0.,   0.,  13.,  73.,   0.,   0.,   1.,   4.,   0.,   0.,   0.,\n",
       "           0.,   1.,   1.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           3.,   0.,  36., 136., 127.,  62.,  54.,   0.,   0.,   0.,   1.,   3.,\n",
       "           4.,   0.,   0.,   3.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           6.,   0., 102., 204., 176., 134., 144., 123.,  23.,   0.,   0.,   0.,\n",
       "           0.,  12.,  10.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0., 155., 236., 207., 178., 107., 156., 161., 109.,  64.,  23.,\n",
       "          77., 130.,  72.,  15.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "           0.,  69., 207., 223., 218., 216., 216., 163., 127., 121., 122., 146.,\n",
       "         141.,  88., 172.,  66.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,\n",
       "           0., 200., 232., 232., 233., 229., 223., 223., 215., 213., 164., 127.,\n",
       "         123., 196., 229.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0., 183., 225., 216., 223., 228., 235., 227., 224., 222., 224., 221.,\n",
       "         223., 245., 173.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0., 193., 228., 218., 213., 198., 180., 212., 210., 211., 213., 223.,\n",
       "         220., 243., 202.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   3.,   0.,\n",
       "          12., 219., 220., 212., 218., 192., 169., 227., 208., 218., 224., 212.,\n",
       "         226., 197., 209.,  52.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,   0.,\n",
       "          99., 244., 222., 220., 218., 203., 198., 221., 215., 213., 222., 220.,\n",
       "         245., 119., 167.,  56.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,   0.,\n",
       "          55., 236., 228., 230., 228., 240., 232., 213., 218., 223., 234., 217.,\n",
       "         217., 209.,  92.,   0.],\n",
       "        [  0.,   0.,   1.,   4.,   6.,   7.,   2.,   0.,   0.,   0.,   0.,   0.,\n",
       "         237., 226., 217., 223., 222., 219., 222., 221., 216., 223., 229., 215.,\n",
       "         218., 255.,  77.,   0.],\n",
       "        [  0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  62., 145., 204.,\n",
       "         228., 207., 213., 221., 218., 208., 211., 218., 224., 223., 219., 215.,\n",
       "         224., 244., 159.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,  18.,  44.,  82., 107., 189., 228., 220., 222.,\n",
       "         217., 226., 200., 205., 211., 230., 224., 234., 176., 188., 250., 248.,\n",
       "         233., 238., 215.,   0.],\n",
       "        [  0.,  57., 187., 208., 224., 221., 224., 208., 204., 214., 208., 209.,\n",
       "         200., 159., 245., 193., 206., 223., 255., 255., 221., 234., 221., 211.,\n",
       "         220., 232., 246.,   0.],\n",
       "        [  3., 202., 228., 224., 221., 211., 211., 214., 205., 205., 205., 220.,\n",
       "         240.,  80., 150., 255., 229., 221., 188., 154., 191., 210., 204., 209.,\n",
       "         222., 228., 225.,   0.],\n",
       "        [ 98., 233., 198., 210., 222., 229., 229., 234., 249., 220., 194., 215.,\n",
       "         217., 241.,  65.,  73., 106., 117., 168., 219., 221., 215., 217., 223.,\n",
       "         223., 224., 229.,  29.],\n",
       "        [ 75., 204., 212., 204., 193., 205., 211., 225., 216., 185., 197., 206.,\n",
       "         198., 213., 240., 195., 227., 245., 239., 223., 218., 212., 209., 222.,\n",
       "         220., 221., 230.,  67.],\n",
       "        [ 48., 203., 183., 194., 213., 197., 185., 190., 194., 192., 202., 214.,\n",
       "         219., 221., 220., 236., 225., 216., 199., 206., 186., 181., 177., 172.,\n",
       "         181., 205., 206., 115.],\n",
       "        [  0., 122., 219., 193., 179., 171., 183., 196., 204., 210., 213., 207.,\n",
       "         211., 210., 200., 196., 194., 191., 195., 191., 198., 192., 176., 156.,\n",
       "         167., 177., 210.,  92.],\n",
       "        [  0.,   0.,  74., 189., 212., 191., 175., 172., 175., 181., 185., 188.,\n",
       "         189., 188., 193., 198., 204., 209., 210., 210., 211., 188., 188., 194.,\n",
       "         192., 216., 170.,   0.],\n",
       "        [  2.,   0.,   0.,   0.,  66., 200., 222., 237., 239., 242., 246., 243.,\n",
       "         244., 221., 220., 193., 191., 179., 182., 182., 181., 176., 166., 168.,\n",
       "          99.,  58.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  40.,  61.,  44.,  72.,  41.,\n",
       "          35.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]#28*28の配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train #X_train[0]の配列なら正解は9となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "ds_train = TensorDataset(X_train, t_train)\n",
    "ds_test = TensorDataset(X_test, t_test)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "n_in = 28*28\n",
    "n_mid = 128\n",
    "n_out = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(n_in, n_mid),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(n_mid, n_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4237, -0.1674, -0.8751,  ...,  0.1653,  0.6152,  0.7895],\n",
       "        [-0.1744,  0.0421, -0.5306,  ...,  0.3412,  0.3141,  0.8778],\n",
       "        [ 0.1035, -0.2449, -0.7750,  ...,  0.4933,  0.1405,  0.9180],\n",
       "        ...,\n",
       "        [ 0.0193,  0.0639, -0.5888,  ...,  0.4397,  0.3247,  0.8677],\n",
       "        [-0.1044,  0.2914, -0.6018,  ...,  0.3503,  0.3211,  0.8146],\n",
       "        [-0.1886,  0.2703, -0.8232,  ...,  0.8169,  0.4797,  0.7427]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0527, 0.0680, 0.0335,  ..., 0.0949, 0.1488, 0.1771],\n",
       "        [0.0651, 0.0808, 0.0456,  ..., 0.1090, 0.1061, 0.1864],\n",
       "        [0.0850, 0.0600, 0.0353,  ..., 0.1255, 0.0882, 0.1919],\n",
       "        ...,\n",
       "        [0.0718, 0.0751, 0.0391,  ..., 0.1093, 0.0974, 0.1677],\n",
       "        [0.0699, 0.1038, 0.0425,  ..., 0.1101, 0.1070, 0.1752],\n",
       "        [0.0606, 0.0958, 0.0321,  ..., 0.1656, 0.1182, 0.1537]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ソフトマックス関数(各値が出力される確率を返す)\n",
    "from torch.nn import functional as F\n",
    "\n",
    "F.softmax(model(X_train), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(X_train), dim=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尤度関数\n",
    "#0.1771*0.0651*0.0850．．．正解の確率を掛け合わせたもの（1に近いほど良い）\n",
    "\n",
    "#損失関数：E＝-log(L) 交差エントロピー誤差関数\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3861, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(X_train), t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train:[loss=0.899,accuracy=0.712], test:[loss:0.702, accuracy=0.749]\n",
      "epoch:1, train:[loss=0.709,accuracy=0.741], test:[loss:0.733, accuracy=0.739]\n",
      "epoch:2, train:[loss=0.702,accuracy=0.746], test:[loss:0.694, accuracy=0.735]\n",
      "epoch:3, train:[loss=0.664,accuracy=0.755], test:[loss:0.672, accuracy=0.765]\n",
      "epoch:4, train:[loss=0.648,accuracy=0.763], test:[loss:0.619, accuracy=0.780]\n",
      "epoch:5, train:[loss=0.645,accuracy=0.764], test:[loss:0.646, accuracy=0.764]\n",
      "epoch:6, train:[loss=0.637,accuracy=0.769], test:[loss:0.636, accuracy=0.770]\n",
      "epoch:7, train:[loss=0.630,accuracy=0.766], test:[loss:0.651, accuracy=0.753]\n",
      "epoch:8, train:[loss=0.632,accuracy=0.769], test:[loss:0.620, accuracy=0.783]\n",
      "epoch:9, train:[loss=0.617,accuracy=0.776], test:[loss:0.607, accuracy=0.770]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    train_num = 0\n",
    "    train_true_num = 0\n",
    "    test_num = 0\n",
    "    test_true_num = 0\n",
    "    \n",
    "    model.train()\n",
    "    for X, t in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        y = model(X)\n",
    "        loss = loss_fn(y, t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #予測値\n",
    "        pred = y.argmax(1) #横方向に最大値をとる（縦に取る場合はargmax(0)）\n",
    "        loss_train.append(loss.tolist())\n",
    "        train_num +=t.shape[0] #データの長さ\n",
    "        train_true_num +=(pred==t).sum().item()\n",
    "        \n",
    "    model.eval()\n",
    "    for X, t in loader_train:\n",
    "        y = model(X)\n",
    "        loss = loss_fn(y, t)\n",
    "        #予測値\n",
    "        pred = y.argmax(1) #横方向に最大値をとる（縦に取る場合はargmax[1]）\n",
    "        loss_test.append(loss.tolist())\n",
    "        test_num +=t.shape[0] #データの長さ\n",
    "        test_true_num +=(pred==t).sum().item()\n",
    "    \n",
    "    print('epoch:{}, train:[loss={:.3F},accuracy={:.3F}], test:[loss:{:.3F}, accuracy={:.3F}]'.\\\n",
    "         format(epoch, np.mean(loss_train), train_true_num/train_num, np.mean(loss_test), test_true_num/test_num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
